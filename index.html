<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="Pedestrian Intention Prediction: A Multi-Task Perspective - Smail Ait Bouhsain, Saeed Saadatnejad, Alexandre Alahi">
  <meta name="description" content="This paper addresses the challenge of forecasting pedestrians' intentions for autonomous vehicles by jointly predicting their intentions and visual states, including bounding boxes, using a recurrent neural network with a multi-task learning approach. Experiments on the JAAD dataset demonstrate its superior performance in intention prediction and competitive bounding box prediction with a simpler, faster architecture.">
  <meta name="keywords" content="pedestrian intention prediction, autonomous vehicles, multi-task learning, recurrent neural networks, LSTM, computer vision, deep learning, behavior prediction, visual state estimation, intelligent transportation systems">
  <meta name="author" content="Smail Ait Bouhsain, Saeed Saadatnejad, Alexandre Alahi">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="VITA-EPFL">
  <meta property="og:title" content="Pedestrian Intention Prediction: A Multi-Task Perspective - Smail Ait Bouhsain, Saeed Saadatnejad, Alexandre Alahi">
  <meta property="og:description" content="This paper addresses the challenge of forecasting pedestrians' intentions for autonomous vehicles by jointly predicting their intentions and visual states, including bounding boxes, using a recurrent neural network with a multi-task learning approach. Experiments on the JAAD dataset demonstrate its superior performance in intention prediction and competitive bounding box prediction with a simpler, faster architecture.">
  <meta property="og:url" content="https://smail8.github.io/pedestrian-intention-prediction/">
  <meta property="og:image" content="https://github.com/Smail8/pedestrian-intention-prediction/tree/master/static/images/poster.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="Pedestrian Intention Prediction: A Multi-Task Perspective - Smail Ait Bouhsain, Saeed Saadatnejad, Alexandre Alahi - Research Preview">
  <meta property="article:published_time" content="2020-10-20T00:00:00.000Z">
  <meta property="article:author" content="Smail Ait Bouhsain">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="pedestrian intention prediction">
  <meta property="article:tag" content="autonomous vehicles">
  <meta property="article:tag" content="multi-task learning">
  <meta property="article:tag" content="recurrent neural networks">
  <meta property="article:tag" content="LSTM">
  <meta property="article:tag" content="computer vision">
  <meta property="article:tag" content="deep learning">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@EPFL">
  <meta name="twitter:creator" content="@Sm1Le8B">
  <meta name="twitter:title" content="Pedestrian Intention Prediction: A Multi-Task Perspective - Smail Ait Bouhsain, Saeed Saadatnejad, Alexandre Alahi">
  <meta name="twitter:description" content="This paper addresses the challenge of forecasting pedestrians' intentions for autonomous vehicles by jointly predicting their intentions and visual states, including bounding boxes, using a recurrent neural network with a multi-task learning approach. Experiments on the JAAD dataset demonstrate its superior performance in intention prediction and competitive bounding box prediction with a simpler, faster architecture.">
  <meta name="twitter:image" content="https://github.com/Smail8/pedestrian-intention-prediction/tree/master/static/images/model.png">
  <meta name="twitter:image:alt" content="Pedestrian Intention Prediction: A Multi-Task Perspective - Smail Ait Bouhsain, Saeed Saadatnejad, Alexandre Alahi - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Pedestrian Intention Prediction: A Multi-Task Perspective">
  <meta name="citation_author" content="Ait Bouhsain, Smail">
  <meta name="citation_author" content="Saadatnejad, Saeed">
  <meta name="citation_author" content="Alahi, Alexandre">
  <meta name="citation_publication_date" content="2020">
  <meta name="citation_conference_title" content="9th Symposium of the European Association for Research in Transportation (hEART 2020)">
  <meta name="citation_pdf_url" content="https://arxiv.org/pdf/2010.10270">

  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">

  <title>Pedestrian Intention Prediction: A Multi-Task Perspective - Smail Ait Bouhsain, Saeed Saadatnejad, Alexandre Alahi | Academic Research</title>

  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.png">
  <link rel="apple-touch-icon" href="static/images/favicon.png">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Pedestrian Intention Prediction: A Multi-Task Perspective",
    "description": "This paper addresses the challenge of forecasting pedestrians' intentions for autonomous vehicles by jointly predicting their intentions and visual states, including bounding boxes, using a recurrent neural network with a multi-task learning approach. Experiments on the JAAD dataset demonstrate its superior performance in intention prediction and competitive bounding box prediction with a simpler, faster architecture.",
    "author": [
      {
        "@type": "Person",
        "name": "Ait Bouhsain, Smail",
        "affiliation": {
          "@type": "Organization",
          "name": "VITA-EPFL"
        }
      },
      {
        "@type": "Person",
        "name": "Saadatnejad, Saeed",
        "affiliation": {
          "@type": "Organization",
          "name": "VITA-EPFL"
        }
      },
      {
        "@type": "Person",
        "name": "Alahi, Alexandre",
        "affiliation": {
          "@type": "Organization",
          "name": "VITA-EPFL"
        }
      }
    ],
    "datePublished": "2020-10-20",
    "publisher": {
      "@type": "Organization",
      "name": "9th Symposium of the European Association for Research in Transportation (hEART 2020)"
    },
    "url": "https://smail8.github.io/pedestrian-intention-prediction/",
    "image": "https://github.com/Smail8/pedestrian-intention-prediction/tree/master/static/images/model.png",
    "keywords": [
      "pedestrian intention prediction", "autonomous vehicles", "multi-task learning", "recurrent neural networks", "LSTM", "computer vision", "deep learning", "behavior prediction", "visual state estimation", "intelligent transportation systems"
    ],
    "abstract": "In order to be globally deployed, autonomous cars must guarantee the safety of pedestrians. This is the reason why forecasting pedestrians' intentions sufficiently in advance is one of the most critical and challenging tasks for autonomous vehicles. This work tries to solve this problem by jointly predicting the intention and visual states of pedestrians. In terms of visual states, whereas previous work focused on x-y coordinates, we will also predict the size and indeed the whole bounding box of the pedestrian. The method is a recurrent neural network in a multi-task learning approach. It has one head that predicts the intention of the pedestrian for each one of its future position and another one predicting the visual states of the pedestrian. Experiments on the JAAD dataset show the superiority of the performance of our method compared to previous works for intention prediction. Also, although its simple architecture (more than 2 times faster), the performance of the bounding box prediction is comparable to the ones yielded by much more complex architectures.",
    "citation": "@article{ait2020pedestrian,
      title={Pedestrian intention prediction: A multi-task perspective},
      author={Ait Bouhsain, Smail and Saadatnejad, Saeed and Alahi, Alexandre},
      journal={9th Symposium of the European Association for Research in Transportation (hEART 2020)},
      year={2020}
    }",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://smail8.github.io/pedestrian-intention-prediction/"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "Pedestrian Intention Prediction"
      },
      {
        "@type": "Thing", 
        "name": "Autonomous Vehicles"
      },
      {
        "@type": "Thing", 
        "name": "Multi-Task Learning"
      },
      {
        "@type": "Thing", 
        "name": "Recurrent Neural Networks"
      },
      {
        "@type": "Thing", 
        "name": "Deep Learning"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "VITA-EPFL",
    "url": "https://laas.fr",
    "logo": "https://github.com/Smail8/pedestrian-intention-prediction/tree/master/static/images/epfl_logo.png",
    "sameAs": [
      "https://twitter.com/LaasCNRS",
      "https://github.com/Smail8/pedestrian-intention-prediction",
    ]
  }
  </script>
</head>

<body>
  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">Pedestrian Intention Prediction: A Multi-Task Perspective</h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block"><a href="https://smail8.github.io" target="_blank">Smail Ait Bouhsain</a>,</span>
                <span class="author-block"><a href="https://saeedsaadatnejad.github.io/" target="_blank">Saeed Saadatnejad</a>,</span>
                <span class="author-block"><a href="https://people.epfl.ch/alexandre.alahi/" target="_blank">Alexandre Alahi</a></span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block">VITA-EPFL<br>9th Symposium of the European Association for Research in Transportation (hEART 2020)</span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/2010.10270" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://github.com/vita-epfl/bounding-box-prediction" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2010.10270" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>HAL</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <!-- Teaser video-->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
            <figure class="image">
              <img src="static/images/visualizations.png" alt="Teaser Image">
            </figure>
            <div style="margin-top: 20px;"></div> <!-- Added vertical space -->
            <h2 class="subtitle has-text-centered">
                Ensuring pedestrian safety is a critical challenge for the global deployment of autonomous vehicles. This work addresses this issue by forecasting pedestrians' intentions and visual states using a recurrent neural network with a multi-task learning approach. Unlike prior methods that focused solely on x-y coordinates, this approach predicts the entire bounding box of pedestrians. The model features two heads: one for predicting pedestrian intentions at future positions and another for visual state estimation. Experiments on the JAAD dataset demonstrate superior intention prediction performance and competitive bounding box prediction accuracy, achieved with a simpler and faster architecture compared to more complex alternatives.
            </h2>
        </div>
      </div>
    </section>
    <!-- End teaser video -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                In order to be globally deployed, autonomous cars must guarantee the safety of pedestrians. This is the reason why forecasting pedestrians' intentions sufficiently in advance is one of the most critical and challenging tasks for autonomous vehicles. This work tries to solve this problem by jointly predicting the intention and visual states of pedestrians. In terms of visual states, whereas previous work focused on x-y coordinates, we will also predict the size and indeed the whole bounding box of the pedestrian. The method is a recurrent neural network in a multi-task learning approach. It has one head that predicts the intention of the pedestrian for each one of its future position and another one predicting the visual states of the pedestrian. Experiments on the JAAD dataset show the superiority of the performance of our method compared to previous works for intention prediction. Also, although its simple architecture (more than 2 times faster), the performance of the bounding box prediction is comparable to the ones yielded by much more complex architectures.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->

    <!-- Neural Network Image -->
    <section class="section hero is-small">
      <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
        <h2 class="title is-3">Proposed Model</h2>
        <figure class="image">
          <img src="static/images/model.png" alt="Diagram of Geometric Reasoning Networks (GRN)">
        </figure>
        <div style="margin-top: 20px;"></div> <!-- Added vertical space -->
        <p class="subtitle">
          The proposed multi-task learning network is an LSTM based encoder-decoder architecture that leverages the position and dimensions of the observed bounding box as well as their velocity in order to predict the future bounding boxes of pedestrians as well as a sequence of future intentions.
        </p>
      </div>
      </div>
    </section>
    <!-- End Neural Network Image -->

    <!-- Visualizations Section -->
    <section class="section hero is-small">
      <div class="hero-body">
        <div class="container"></div>
          <h2 class="title is-3 has-text-centered">Visualizations</h2>
          <div class="columns is-centered is-multiline">
            <!-- First Image -->
            <div class="column is-four-fifths has-text-centered">
              <figure class="image">
                <img src="static/images/vis2.png" alt="Qualitative Results 1">
              </figure>
            </div>
            <!-- Second Image -->
            <div class="column is-four-fifths has-text-centered" style="margin-top: 2rem;">
              <figure class="image">
                <img src="static/images/vis3.png" alt="Qualitative Results 2">
              </figure>
            </div>
            <!-- Third and Fourth Images Side by Side -->
            <div class="columns is-centered" style="margin-top: 2rem;">
              <div class="column is-half has-text-centered">
                <figure class="image">
                  <img src="static/images/res2.gif" alt="Qualitative Results 3">
                </figure>
              </div>
              <div class="column is-half has-text-centered">
                <figure class="image">
                  <img src="static/images/res1.gif" alt="Qualitative Results 4">
                </figure>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End Visualizations Section -->

    <!--BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="bibtex-header">
          <h2 class="title">BibTeX</h2>
          <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
            <i class="fas fa-copy"></i>
            <span class="copy-text">Copy</span>
          </button>
        </div>
        <pre id="bibtex-code">
          <code>
            @article{ait2020pedestrian,
              title={Pedestrian intention prediction: A multi-task perspective},
              author={Ait Bouhsain, Smail and Saadatnejad, Saeed and Alahi, Alexandre},
              journal={9th Symposium of the European Association for Research in Transportation (hEART 2020)},
              year={2020}
            }
          </code>
        </pre>
      </div>
    </section>
    <!--End BibTex citation -->
  </main>


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Default Statcounter code for Pedestrian Intention Prediction https://smail8.github.io/pedestrian-intention-prediction/ -->
  <script type="text/javascript">
    var sc_project=13200349; 
    var sc_invisible=1; 
    var sc_security="5f05eb98"; 
  </script>
  <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
  <noscript>
    <div class="statcounter">
      <a title="web stats"href="https://statcounter.com/" target="_blank">
        <img class="statcounter" src="https://c.statcounter.com/13200349/0/5f05eb98/1/" alt="web stats" referrerPolicy="no-referrer-when-downgrade">
      </a>
    </div>
  </noscript>
  <!-- End of Statcounter Code -->

</body>
</html>
